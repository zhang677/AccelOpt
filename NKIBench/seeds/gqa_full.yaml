test_name: gqa_full

parameters:
- B
- N
- QH
- KH
- D

input: |
  q = np.random.normal(loc=0, scale=1.0, size=(B, N, QH, D)).astype(np.float32)
  k = np.random.normal(loc=0, scale=1.0, size=(B, N, KH, D)).astype(np.float32)
  v = np.random.normal(loc=0, scale=1.0, size=(B, N, KH, D)).astype(np.float32)
  return [q, k, v]

impl: |
  def forward(q, k, v):
    n_rep = QH // KH
    xk = np.repeat(k, n_rep, axis=2)
    xv = np.repeat(v, n_rep, axis=2)
    xq = q.transpose(0, 2, 1, 3)
    xk = xk.transpose(0, 2, 1, 3)
    xv = xv.transpose(0, 2, 1, 3)

    attention = (xq @ xk.transpose(0, 1, 3, 2)) / np.float32(np.sqrt(D))
    exp_attention = np.exp(attention - np.max(attention, axis=-1, keepdims=True))
    attention = exp_attention / np.sum(exp_attention, axis=-1, keepdims=True)

    output = attention @ xv
    return output


