{
  "name": "e4bd0b77fee4422d8ec199b55137fd9f",
  "definition": "gqa_ragged_prefill_causal_h32_kv4_d128",
  "author": "AccelOpt",
  "spec": {
    "language": "triton",
    "target_hardware": [
      "H100"
    ],
    "entry_point": "main.py::run"
  },
  "sources": [
    {
      "path": "main.py",
      "content": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 8, 'BLOCK_N': 64}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 64}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 128}, num_warps=8, num_stages=2),\n    ],\n    key=['total_q', 'total_kv']\n)\n@triton.jit\ndef gqa_ragged_causal_kernel_optimized(\n    q_ptr, k_ptr, v_ptr,\n    output_ptr, lse_ptr,\n    qo_indptr_ptr, kv_indptr_ptr,\n    sm_scale,\n    total_q, total_kv,\n    stride_q_tok, stride_q_h, stride_q_d,\n    stride_kv_tok, stride_kv_h, stride_kv_d,\n    stride_out_tok, stride_out_h, stride_out_d,\n    stride_lse_tok, stride_lse_h,\n    num_qo_heads,\n    GQA_RATIO: tl.constexpr,\n    BLOCK_M: tl.constexpr,  # Number of query tokens per block\n    BLOCK_N: tl.constexpr,  # Number of KV tokens per block\n    BLOCK_D: tl.constexpr,\n):\n    # Program indices\n    pid_m = tl.program_id(0)      # Token block index\n    pid_kv_h = tl.program_id(1)   # KV head index\n    pid_b = tl.program_id(2)      # Batch index\n\n    # Sequence boundaries for ragged tensors\n    q_start = tl.load(qo_indptr_ptr + pid_b)\n    q_end = tl.load(qo_indptr_ptr + pid_b + 1)\n    kv_start = tl.load(kv_indptr_ptr + pid_b)\n    kv_end = tl.load(kv_indptr_ptr + pid_b + 1)\n\n    num_q_tokens = q_end - q_start\n    num_kv_tokens = kv_end - kv_start\n\n    # Early exit if the program token range is beyond sequence length\n    if (pid_m * BLOCK_M) >= num_q_tokens:\n        return\n\n    # Tile configuration: flattened M-tile (Tokens * GQA_RATIO)\n    BLOCK_QM: tl.constexpr = BLOCK_M * GQA_RATIO\n    \n    # Calculate relative head and token offsets within the flattened block\n    rm = tl.arange(0, BLOCK_QM)\n    token_rel = rm % BLOCK_M\n    head_rel = rm // BLOCK_M\n    \n    # Absolute sequence and head indices\n    q_token_abs = q_start + pid_m * BLOCK_M + token_rel\n    q_head_abs = pid_kv_h * GQA_RATIO + head_rel\n    \n    # Query Mask (checks token sequence range)\n    q_mask = (pid_m * BLOCK_M + token_rel) < num_q_tokens\n    \n    # Dimensional offsets\n    rk = tl.arange(0, BLOCK_N)\n    rd = tl.arange(0, BLOCK_D)\n    \n    # Load Query block [BLOCK_QM, BLOCK_D]\n    offs_q = (\n        q_token_abs[:, None] * stride_q_tok +\n        q_head_abs[:, None] * stride_q_h +\n        rd[None, :] * stride_q_d\n    )\n    q = tl.load(q_ptr + offs_q, mask=q_mask[:, None], other=0.0)\n\n    # Online softmax state and output accumulator\n    m_i = tl.full([BLOCK_QM], -float('inf'), dtype=tl.float32)\n    l_i = tl.zeros([BLOCK_QM], dtype=tl.float32)\n    acc = tl.zeros([BLOCK_QM, BLOCK_D], dtype=tl.float32)\n\n    # Causal logic parameters\n    delta = num_kv_tokens - num_q_tokens\n    kv_limit = tl.minimum(num_kv_tokens, (pid_m + 1) * BLOCK_M + delta)\n    \n    # KV loop: Reuse loaded K and V for all GQA query heads in the tile\n    for kv_block_start in tl.range(0, kv_limit, BLOCK_N):\n        k_mask = (kv_block_start + rk) < num_kv_tokens\n        \n        # Load Key and Value block [BLOCK_N, BLOCK_D]\n        # These only depend on pid_kv_h, shared by the whole GQA group\n        offs_kv = (\n            (kv_start + kv_block_start + rk[:, None]) * stride_kv_tok +\n            pid_kv_h * stride_kv_h +\n            rd[None, :] * stride_kv_d\n        )\n        k = tl.load(k_ptr + offs_kv, mask=k_mask[:, None], other=0.0)\n        v = tl.load(v_ptr + offs_kv, mask=k_mask[:, None], other=0.0)\n        \n        # Compute Attention Logits: Q @ K^T\n        qk = tl.dot(q, tl.trans(k))  # [BLOCK_QM, BLOCK_N]\n        qk *= sm_scale\n        \n        # Apply masks: sequence padding, causal, and KV padding\n        q_pos_in_seq = pid_m * BLOCK_M + token_rel\n        kv_pos_in_seq = kv_block_start + rk\n        causal_mask = kv_pos_in_seq[None, :] < (q_pos_in_seq[:, None] + 1 + delta)\n        \n        qk = tl.where(q_mask[:, None] & causal_mask & k_mask[None, :], qk, -float('inf'))\n        \n        # Online softmax update\n        m_i_new = tl.maximum(m_i, tl.max(qk, 1))\n        p = tl.exp(qk - m_i_new[:, None])\n        alpha = tl.exp(m_i - m_i_new)\n        l_i_new = alpha * l_i + tl.sum(p, 1)\n        \n        # Update accumulator\n        acc *= alpha[:, None]\n        acc = tl.dot(p.to(v.dtype), v, acc)\n        \n        m_i = m_i_new\n        l_i = l_i_new\n\n    # Final normalization and LSE calculation\n    acc = acc / l_i[:, None]\n    lse_val = (m_i + tl.log(l_i)) * 1.44269504  # 1.44269504 is log2(e)\n    \n    # Store output and LSE\n    offs_out = (\n        q_token_abs[:, None] * stride_out_tok +\n        q_head_abs[:, None] * stride_out_h +\n        rd[None, :] * stride_out_d\n    )\n    tl.store(output_ptr + offs_out, acc.to(output_ptr.dtype.element_ty), mask=q_mask[:, None])\n    \n    offs_lse = q_token_abs * stride_lse_tok + q_head_abs * stride_lse_h\n    tl.store(lse_ptr + offs_lse, lse_val, mask=q_mask)\n\n@torch.no_grad()\ndef run(q, k, v, qo_indptr, kv_indptr, sm_scale):\n    total_q, num_qo_heads, head_dim = q.shape\n    total_kv, num_kv_heads, _ = k.shape\n    num_batches = qo_indptr.shape[0] - 1\n    \n    output = torch.empty((total_q, num_qo_heads, head_dim), dtype=q.dtype, device=q.device)\n    lse = torch.empty((total_q, num_qo_heads), dtype=torch.float32, device=q.device)\n    \n    GQA_RATIO = num_qo_heads // num_kv_heads\n    \n    # Identify the maximum sequence length for grid dimension 0\n    q_lens = qo_indptr[1:] - qo_indptr[:-1]\n    max_q_tokens = torch.max(q_lens).item() if q_lens.numel() > 0 else 0\n    \n    def grid_fn(META):\n        return (\n            triton.cdiv(max_q_tokens, META['BLOCK_M']),\n            num_kv_heads,\n            num_batches\n        )\n    \n    gqa_ragged_causal_kernel_optimized[grid_fn](\n        q_ptr=q, k_ptr=k, v_ptr=v,\n        output_ptr=output, lse_ptr=lse,\n        qo_indptr_ptr=qo_indptr, kv_indptr_ptr=kv_indptr,\n        sm_scale=sm_scale,\n        total_q=total_q, total_kv=total_kv,\n        stride_q_tok=q.stride(0), stride_q_h=q.stride(1), stride_q_d=q.stride(2),\n        stride_kv_tok=k.stride(0), stride_kv_h=k.stride(1), stride_kv_d=k.stride(2),\n        stride_out_tok=output.stride(0), stride_out_h=output.stride(1), stride_out_d=output.stride(2),\n        stride_lse_tok=lse.stride(0), stride_lse_h=lse.stride(1),\n        num_qo_heads=num_qo_heads,\n        GQA_RATIO=GQA_RATIO,\n        BLOCK_D=head_dim,\n    )\n    \n    return output, lse"
    }
  ],
  "description": "89356b1e4714476fb658a3f363d88fa1_plan_1_0"
}