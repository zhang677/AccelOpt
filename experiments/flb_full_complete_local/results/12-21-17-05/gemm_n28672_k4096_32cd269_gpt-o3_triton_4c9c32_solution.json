{
  "name": "c4d2fd6abce148dfb9a6c9ac4d233e50",
  "definition": "gemm_n28672_k4096",
  "author": "AccelOpt",
  "spec": {
    "language": "triton",
    "target_hardware": [
      "H100"
    ],
    "entry_point": "main.py::run",
    "dependencies": []
  },
  "sources": [
    {
      "path": "main.py",
      "content": "import torch\nimport triton\nimport triton.language as tl\n\n# --------------------------------------------------------------\n# GEMM kernel – unchanged (already stride‑aware)\n# --------------------------------------------------------------\n@triton.jit\ndef gemm_kernel(\n    A_ptr,\n    B_ptr,\n    C_ptr,\n    M,\n    N,\n    K,\n    stride_am,\n    stride_ak,\n    stride_bn,   # stride for the logical “N” dimension of B\n    stride_bk,   # stride for the logical “K” dimension of B\n    stride_cm,\n    stride_cn,\n    BLOCK_M: tl.constexpr,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    \"\"\"C = A @ B.T   (A: [M, K], B: [N, K], C: [M, N])\"\"\"\n    pid_m = tl.program_id(0)          # row‑tile index\n    pid_n = tl.program_id(1)          # col‑tile index\n\n    # ----------------------------------------------------------\n    # Tile offsets\n    # ----------------------------------------------------------\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)   # [BLOCK_M]\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)   # [BLOCK_N]\n    offs_k = tl.arange(0, BLOCK_K)                     # [BLOCK_K]\n\n    # Pointers to the current tile of A and B\n    a_ptrs = A_ptr + (offs_m[:, None] * stride_am +\n                     offs_k[None, :] * stride_ak)      # [BLOCK_M, BLOCK_K]\n    b_ptrs = B_ptr + (offs_n[None, :] * stride_bn +\n                     offs_k[:, None] * stride_bk)      # [BLOCK_K, BLOCK_N]\n\n    # Accumulator in fp32\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n\n    # ----------------------------------------------------------\n    # Main K‑loop (tiling over the reduction dimension)\n    # ----------------------------------------------------------\n    num_k_iters = tl.cdiv(K, BLOCK_K)\n    for _ in range(num_k_iters):\n        a = tl.load(\n            a_ptrs,\n            mask=(offs_m[:, None] < M) & (offs_k[None, :] < K),\n            other=0.0,\n        )\n        b = tl.load(\n            b_ptrs,\n            mask=(offs_n[None, :] < N) & (offs_k[:, None] < K),\n            other=0.0,\n        )\n        acc += tl.dot(a, b)\n\n        # advance to the next K‑tile\n        offs_k += BLOCK_K\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n\n    # ----------------------------------------------------------\n    # Write back result\n    # ----------------------------------------------------------\n    c_ptrs = C_ptr + (offs_m[:, None] * stride_cm +\n                      offs_n[None, :] * stride_cn)\n    tl.store(\n        c_ptrs,\n        acc.to(tl.float16),\n        mask=(offs_m[:, None] < M) & (offs_n[None, :] < N),\n    )\n\n\n# --------------------------------------------------------------\n# Host‑side launcher – **no transpose of B any more**\n# --------------------------------------------------------------\ndef run(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    High‑performance GEMM for the fixed shape:\n        A : [M, 4096]   (float16)\n        B : [28672, 4096] (float16)   <-- **used directly**, no copy\n\n    Returns C : [M, 28672] (float16)\n    \"\"\"\n    # ------------------------------------------------------------------\n    # sanity checks and device handling\n    # ------------------------------------------------------------------\n    if A.ndim != 2 or B.ndim != 2:\n        raise ValueError(\"A and B must be 2‑D tensors\")\n    if A.shape[1] != 4096 or B.shape[1] != 4096 or B.shape[0] != 28672:\n        raise ValueError(\"Expected shapes: A [M, 4096], B [28672, 4096]\")\n    if A.dtype != torch.float16 or B.dtype != torch.float16:\n        raise TypeError(\"A and B must be torch.float16\")\n    if not torch.cuda.is_available():\n        raise RuntimeError(\"CUDA is required to run this Triton kernel\")\n\n    device = torch.device(\"cuda\")\n    A = A.to(device) if not A.is_cuda else A\n    B = B.to(device) if not B.is_cuda else B\n\n    # ------------------------------------------------------------------\n    # No one‑time transpose; we just pass B with its native strides\n    # ------------------------------------------------------------------\n    M = A.shape[0]\n    N = 28672            # fixed by the problem definition\n    K = 4096\n\n    # Output tensor\n    C = torch.empty((M, N), device=device, dtype=torch.float16)\n\n    # --------------------------------------------------------------\n    # Tile configuration (same as baseline – empirically fast)\n    # --------------------------------------------------------------\n    BLOCK_M, BLOCK_N, BLOCK_K = 128, 256, 64\n    NUM_WARPS, NUM_STAGES = 8, 4\n\n    grid = (triton.cdiv(M, BLOCK_M), triton.cdiv(N, BLOCK_N))\n\n    # --------------------------------------------------------------\n    # Launch the kernel with the original B and its strides\n    # --------------------------------------------------------------\n    gemm_kernel[grid](\n        A,                         # [M, K]\n        B,                         # original layout [N, K]\n        C,\n        M, N, K,\n        A.stride(0), A.stride(1),          # stride_am, stride_ak\n        B.stride(0), B.stride(1),          # stride_bn = K (=4096), stride_bk = 1\n        C.stride(0), C.stride(1),          # stride_cm, stride_cn\n        BLOCK_M=BLOCK_M,\n        BLOCK_N=BLOCK_N,\n        BLOCK_K=BLOCK_K,\n        num_warps=NUM_WARPS,\n        num_stages=NUM_STAGES,\n    )\n    torch.cuda.synchronize()\n    return C\n\n\n# ------------------------------------------------------------------\n# Simple correctness test (run when the file is executed directly)\n# ------------------------------------------------------------------\nif __name__ == \"__main__\":\n    torch.manual_seed(0)\n    M_test = 256\n    A_test = torch.randn((M_test, 4096), dtype=torch.float16, device=\"cuda\")\n    B_test = torch.randn((28672, 4096), dtype=torch.float16, device=\"cuda\")\n\n    # Reference: fp32 accumulation then cast back to fp16\n    C_ref = (A_test.float() @ B_test.t().float()).half()\n\n    C_out = run(A_test, B_test)\n\n    assert torch.allclose(C_ref, C_out, atol=1e-2, rtol=1e-2)\n    print(\"✅ correctness test passed\")"
    }
  ],
  "description": "66765884027648f58531193764175476_plan_1_0"
}