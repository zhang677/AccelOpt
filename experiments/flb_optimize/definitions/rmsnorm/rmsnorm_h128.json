{
  "name": "rmsnorm_h128",
  "op_type": "rmsnorm",
  "axes": {
    "batch_size": {
      "type": "var"
    },
    "hidden_size": {
      "type": "const",
      "value": 128
    }
  },
  "inputs": {
    "hidden_states": {
      "shape": [
        "batch_size",
        "hidden_size"
      ],
      "dtype": "bfloat16"
    },
    "weight": {
      "shape": [
        "hidden_size"
      ],
      "dtype": "bfloat16"
    }
  },
  "outputs": {
    "output": {
      "shape": [
        "batch_size",
        "hidden_size"
      ],
      "dtype": "bfloat16"
    }
  },
  "reference": "import torch\n\n@torch.no_grad()\ndef run(hidden_states, weight):\n    batch_size, hidden_size = hidden_states.shape\n    # Check constants\n    assert hidden_size == 128\n\n    EPS = 1e-6\n\n    x = hidden_states.to(torch.float32)\n    inv_rms = torch.rsqrt(x.pow(2).mean(dim=-1, keepdim=True) + EPS)\n    y = (x * inv_rms) * weight.to(torch.float32)\n    return y.to(hidden_states.dtype)",
  "tags": [
    "status:verified",
    "model:qwen3-30b-a3b"
  ],
  "description": "Root Mean Square Normalization with hidden_size=128. Captured from Qwen3-30B-A3B. Epsilon is fixed at 1e-6."
}