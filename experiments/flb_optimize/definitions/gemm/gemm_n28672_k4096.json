{
  "name": "gemm_n28672_k4096",
  "op_type": "gemm",
  "axes": {
    "M": {
      "type": "var"
    },
    "N": {
      "type": "const",
      "value": 28672
    },
    "K": {
      "type": "const",
      "value": 4096
    }
  },
  "inputs": {
    "A": {
      "shape": [
        "M",
        "K"
      ],
      "dtype": "float16"
    },
    "B": {
      "shape": [
        "N",
        "K"
      ],
      "dtype": "float16"
    }
  },
  "outputs": {
    "C": {
      "shape": [
        "M",
        "N"
      ],
      "dtype": "float16"
    }
  },
  "reference": "import torch\n\ndef run(A, B):\n    C = torch.matmul(A, B.T)\n    return C",
  "tags": [
    "status:verified",
    "model:llama-3.1-8b"
  ],
  "description": "General matrix multiply (GEMM) C = A @ B.T. Captured from Llama 3.1 8B mlp.gate_up_proj."
}