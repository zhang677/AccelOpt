{
  "name": "claude-opus-4-1_triton_79b898",
  "definition": "gemm_n28672_k4096",
  "author": "claude-opus-4-1-20250805",
  "spec": {
    "language": "triton",
    "target_hardware": [
      "B200"
    ],
    "entry_point": "main.py::run",
    "dependencies": []
  },
  "sources": [
    {
      "path": "main.py",
      "content": "import torch\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef gemm_kernel(\n    a_ptr, b_ptr, c_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_SIZE_M: tl.constexpr,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    # Program ID\n    pid = tl.program_id(axis=0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    \n    # 2D grid mapping\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n    \n    # Skip if out of bounds\n    if pid_m >= num_pid_m:\n        return\n\n    # Block indices\n    offs_am = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_bn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Accumulator\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    # Loop over K dimension\n    for k in range(0, K, BLOCK_SIZE_K):\n        # Compute current k offsets\n        curr_k = k + offs_k\n        \n        # Load tiles with boundary checks\n        a_ptrs = a_ptr + (offs_am[:, None] * stride_am + curr_k[None, :] * stride_ak)\n        b_ptrs = b_ptr + (offs_bn[:, None] * stride_bn + curr_k[None, :] * stride_bk)\n        \n        a_mask = (offs_am[:, None] < M) & (curr_k[None, :] < K)\n        b_mask = (offs_bn[:, None] < N) & (curr_k[None, :] < K)\n        \n        a = tl.load(a_ptrs, mask=a_mask, other=0.0)\n        b = tl.load(b_ptrs, mask=b_mask, other=0.0)\n        \n        # Matrix multiply and accumulate - b is already transposed in memory layout\n        accumulator += tl.dot(a, b.T, allow_tf32=True)\n    \n    # Convert back to fp16 and store\n    c = accumulator.to(tl.float16)\n    \n    # Store output with boundary checks\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n    \n    tl.store(c_ptrs, c, mask=c_mask)\n\ndef run(A, B):\n    # Handle device management\n    device_a = A.device\n    device_b = B.device\n    \n    # Move to GPU if needed\n    if A.device.type == 'cpu':\n        if not torch.cuda.is_available():\n            raise RuntimeError(\"CUDA is not available but GPU tensors are required\")\n        A = A.cuda()\n    \n    if B.device.type == 'cpu':\n        if not torch.cuda.is_available():\n            raise RuntimeError(\"CUDA is not available but GPU tensors are required\")\n        B = B.cuda()\n    \n    # Ensure tensors are on the same GPU\n    if A.device != B.device:\n        B = B.to(A.device)\n    \n    # Get dimensions\n    M = A.shape[0]\n    N = 28672  # constant\n    K = 4096   # constant\n    \n    # Allocate output\n    C = torch.empty((M, N), device=A.device, dtype=torch.float16)\n    \n    # Block sizes optimized for B200\n    BLOCK_SIZE_M = 128\n    BLOCK_SIZE_N = 128\n    BLOCK_SIZE_K = 64\n    \n    # Grid configuration\n    def grid(META):\n        return (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),)\n    \n    # Launch kernel\n    gemm_kernel[grid](\n        A, B, C,\n        M, N, K,\n        A.stride(0), A.stride(1),\n        B.stride(0), B.stride(1),\n        C.stride(0), C.stride(1),\n        BLOCK_SIZE_M=BLOCK_SIZE_M,\n        BLOCK_SIZE_N=BLOCK_SIZE_N,\n        BLOCK_SIZE_K=BLOCK_SIZE_K,\n    )\n    \n    # Move result back to original device if needed\n    if device_a.type == 'cpu':\n        C = C.cpu()\n    elif device_a != C.device:\n        C = C.to(device_a)\n    \n    return C"
    }
  ],
  "description": "claude-opus-4-1-20250805 optimized kernel for gemm_n28672_k4096 (round 3)"
}