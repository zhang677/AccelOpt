{
  "name": "gemini-2.5-pro_triton_05pwmx",
  "definition": "fused_add_rmsnorm_h7168",
  "author": "gemini-2.5-pro",
  "spec": {
    "language": "triton",
    "target_hardware": [
      "B200"
    ],
    "entry_point": "main.py::run",
    "dependencies": []
  },
  "sources": [
    {
      "path": "main.py",
      "content": "import torch\nimport triton\nimport triton.language as tl\nimport math\n\n# Reference implementation for correctness check\n@torch.no_grad()\ndef reference_run(hidden_states, residual, weight):\n    \"\"\"\n    Reference PyTorch implementation for fused_add_rmsnorm_h7168.\n    \"\"\"\n    _, hidden_size = hidden_states.shape\n    # Check constants\n    assert hidden_size == 7168\n\n    EPS = 1e-6\n\n    x = hidden_states.to(torch.float32) + residual.to(torch.float32)\n    inv_rms = torch.rsqrt(x.pow(2).mean(dim=-1, keepdim=True) + EPS)\n    y = (x * inv_rms) * weight.to(torch.float32)\n    return y.to(hidden_states.dtype)\n\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 1024, 'num_warps': 4, 'num_stages': 2}),\n        triton.Config({'BLOCK_SIZE_N': 1024, 'num_warps': 8, 'num_stages': 2}),\n        triton.Config({'BLOCK_SIZE_N': 2048, 'num_warps': 8, 'num_stages': 2}),\n        triton.Config({'BLOCK_SIZE_N': 4096, 'num_warps': 16, 'num_stages': 2}),\n        # This config is likely optimal as it covers the entire row in one loop iteration\n        triton.Config({'BLOCK_SIZE_N': 8192, 'num_warps': 16, 'num_stages': 2}),\n    ],\n    key=['HIDDEN_SIZE'],\n)\n@triton.jit\ndef _fused_add_rmsnorm_h7168_kernel(\n    # Pointers to tensors\n    hidden_states_ptr,\n    residual_ptr,\n    weight_ptr,\n    output_ptr,\n    # Stride information\n    stride_hs_b,\n    stride_res_b,\n    stride_out_b,\n    # Constants\n    HIDDEN_SIZE: tl.constexpr,\n    EPS: tl.constexpr,\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    \"\"\"\n    Triton kernel for Fused Add + RMSNorm.\n    Each program instance processes one row of the input tensors.\n    \"\"\"\n    # -----------------------------------------------------------\n    # Grid and pointers\n    # -----------------------------------------------------------\n    \n    # Each program instance computes a single row (batch element)\n    pid_b = tl.program_id(axis=0)\n\n    # Pointers to the start of the current row for each tensor\n    row_hs_ptr = hidden_states_ptr + pid_b * stride_hs_b\n    row_res_ptr = residual_ptr + pid_b * stride_res_b\n    row_out_ptr = output_ptr + pid_b * stride_out_b\n    \n    # -----------------------------------------------------------\n    # Pass 1: Compute sum of squares\n    # -----------------------------------------------------------\n    \n    # Accumulator for the sum of squares, initialized to zeros\n    acc = tl.zeros([BLOCK_SIZE_N], dtype=tl.float32)\n    \n    # Loop over the hidden dimension in blocks of BLOCK_SIZE_N\n    for off in range(0, HIDDEN_SIZE, BLOCK_SIZE_N):\n        offsets = off + tl.arange(0, BLOCK_SIZE_N)\n        mask = offsets < HIDDEN_SIZE\n\n        # Load input tensors `hidden_states` and `residual`\n        hs = tl.load(row_hs_ptr + offsets, mask=mask, other=0.0).to(tl.float32)\n        res = tl.load(row_res_ptr + offsets, mask=mask, other=0.0).to(tl.float32)\n        \n        # Fused add\n        x = hs + res\n        \n        # Square and accumulate\n        acc += x * x\n        \n    # Reduce the accumulator to a single scalar value for the variance\n    # tl.sum sums across all threads in a block\n    variance = tl.sum(acc, axis=0) / HIDDEN_SIZE\n    \n    # Compute the inverse root mean square\n    inv_rms = tl.rsqrt(variance + EPS)\n\n    # -----------------------------------------------------------\n    # Pass 2: Normalize and store\n    # -----------------------------------------------------------\n    \n    # Loop over the hidden dimension again to apply the normalization\n    for off in range(0, HIDDEN_SIZE, BLOCK_SIZE_N):\n        offsets = off + tl.arange(0, BLOCK_SIZE_N)\n        mask = offsets < HIDDEN_SIZE\n\n        # Reload inputs\n        hs = tl.load(row_hs_ptr + offsets, mask=mask, other=0.0).to(tl.float32)\n        res = tl.load(row_res_ptr + offsets, mask=mask, other=0.0).to(tl.float32)\n        \n        # Load weight\n        w = tl.load(weight_ptr + offsets, mask=mask).to(tl.float32)\n        \n        # Fused add\n        x = hs + res\n        \n        # Apply RMSNorm and scale by weight\n        normalized_x = x * inv_rms\n        output_val = normalized_x * w\n        \n        # Store the result\n        tl.store(row_out_ptr + offsets, output_val.to(tl.bfloat16), mask=mask)\n\n\ndef run(*args, **kwargs):\n    \"\"\"\n    Wrapper function to run the fused_add_rmsnorm_h7168 Triton kernel.\n\n    Handles device management, tensor validation, grid computation, and kernel launch.\n    Moves data to the GPU if necessary and returns the result on the original device.\n\n    Args:\n        hidden_states (torch.Tensor): Input tensor of shape [batch_size, 7168] and dtype bfloat16.\n        residual (torch.Tensor): Residual tensor of shape [batch_size, 7168] and dtype bfloat16.\n        weight (torch.Tensor): Weight tensor of shape [7168] and dtype bfloat16.\n\n    Returns:\n        torch.Tensor: The output tensor of the same shape and dtype as hidden_states.\n    \"\"\"\n    # 1. Unpack arguments\n    if args:\n        hidden_states, residual, weight = args\n    else:\n        hidden_states = kwargs.get('hidden_states')\n        residual = kwargs.get('residual')\n        weight = kwargs.get('weight')\n        if hidden_states is None or residual is None or weight is None:\n            raise ValueError(\"Missing required arguments: 'hidden_states', 'residual', 'weight'\")\n\n    # 2. Device Management\n    if not torch.cuda.is_available():\n        raise RuntimeError(\"Triton requires a CUDA-enabled GPU, but CUDA is not available.\")\n    \n    # Use the device of the first input tensor as the primary execution device\n    # If the first tensor is on CPU, move all to the default CUDA device\n    primary_input_device = hidden_states.device\n    if primary_input_device.type == 'cpu':\n        execution_device = torch.device('cuda')\n    else:\n        execution_device = primary_input_device\n\n    # Move all tensors to the execution device\n    hidden_states_gpu = hidden_states.to(execution_device)\n    residual_gpu = residual.to(execution_device)\n    weight_gpu = weight.to(execution_device)\n\n    # 3. Shape and DType Validation\n    batch_size, hidden_size = hidden_states.shape\n    \n    if hidden_size != 7168:\n        raise ValueError(f\"hidden_size must be 7168, but got {hidden_size}\")\n    if residual.shape != hidden_states.shape:\n        raise ValueError(f\"Shape of residual {residual.shape} does not match hidden_states {hidden_states.shape}\")\n    if weight.shape != (hidden_size,):\n        raise ValueError(f\"Shape of weight {weight.shape} does not match expected ({hidden_size},)\")\n\n    expected_dtype = torch.bfloat16\n    if hidden_states.dtype != expected_dtype or residual.dtype != expected_dtype or weight.dtype != expected_dtype:\n        raise TypeError(f\"All input tensors must have dtype {expected_dtype}\")\n\n    # 4. Allocate Output Tensor\n    output_gpu = torch.empty_like(hidden_states_gpu)\n\n    # 5. Grid Computation\n    # The grid is 1D, with one program instance per batch element.\n    grid = (batch_size,)\n\n    # 6. Kernel Launch\n    _fused_add_rmsnorm_h7168_kernel[grid](\n        hidden_states_gpu,\n        residual_gpu,\n        weight_gpu,\n        output_gpu,\n        hidden_states_gpu.stride(0),\n        residual_gpu.stride(0),\n        output_gpu.stride(0),\n        HIDDEN_SIZE=hidden_size,\n        EPS=1e-6,\n    )\n\n    # 7. Restore Original Device\n    # Move the output tensor back to the device of the original `hidden_states` tensor\n    output = output_gpu.to(primary_input_device)\n\n    return output"
    }
  ],
  "description": "gemini-2.5-pro optimized kernel for fused_add_rmsnorm_h7168 (round 1)"
}