{
  "name": "gpt-o3_triton_4c17a1",
  "definition": "mla_paged_decode_h16_ckv512_kpe64_ps1",
  "author": "gpt-o3",
  "spec": {
    "language": "triton",
    "target_hardware": [
      "B200"
    ],
    "entry_point": "main.py::run",
    "dependencies": []
  },
  "sources": [
    {
      "path": "main.py",
      "content": "import math\nimport torch\nimport triton\nimport triton.language as tl\n\n\n@triton.jit\ndef _paged_decode_kernel(\n    QN,                     # (B, H, 512)       bf16\n    QP,                     # (B, H, 64)        bf16\n    KC,                     # (P, 512)          bf16\n    KP,                     # (P, 64)           bf16\n    KV_INDICES,             # (N)               int32\n    KV_INDPTR,              # (B + 1)           int32\n    SM_SCALE,               # scalar            fp32\n    OUT,                    # (B, H, 512)       bf16\n    LSE,                    # (B, H)            fp32\n    B: tl.constexpr,\n    H: tl.constexpr,\n    D_CKV: tl.constexpr,\n    D_KPE: tl.constexpr,\n    BLOCK_TOK: tl.constexpr,\n):\n    \"\"\"\n    One Triton program computes a single (batch, head) pair.\n    page_size == 1, num_qo_heads == 16, D_CKV == 512, D_KPE == 64\n    \"\"\"\n\n    pid = tl.program_id(axis=0)\n    b = pid // H                      # batch index\n    h = pid % H                       # head  index\n\n    # ------------------- offsets ------------------- #\n    offs_ckv = tl.arange(0, D_CKV)            # (512,)\n    offs_kpe = tl.arange(0, D_KPE)            # (64,)\n    offs_t   = tl.arange(0, BLOCK_TOK)        # (T,)\n\n    # ------------------- KV range ------------------ #\n    kv_beg = tl.load(KV_INDPTR + b)\n    kv_end = tl.load(KV_INDPTR + b + 1)\n    kv_len = kv_end - kv_beg                  # scalar int32\n\n    # Pointers to output locations\n    ptr_out = OUT + (b * H + h) * D_CKV + offs_ckv\n    ptr_lse = LSE + b * H + h\n\n    # If there is no KV data, write zeros / -inf and exit.\n    if kv_len <= 0:\n        tl.store(ptr_out, tl.zeros([D_CKV], dtype=tl.bfloat16))\n        tl.store(ptr_lse, -float(\"inf\"))\n        return\n\n    # ------------------- load queries -------------- #\n    qn_ptr = QN + (b * H + h) * D_CKV + offs_ckv\n    qp_ptr = QP + (b * H + h) * D_KPE + offs_kpe\n    qn = tl.load(qn_ptr).to(tl.float32)        # (512,)\n    qp = tl.load(qp_ptr).to(tl.float32)        # (64,)\n\n    # ------------------- accumulators -------------- #\n    s_sum = tl.zeros([], dtype=tl.float32)     # scalar\n    w_sum = tl.zeros([D_CKV], dtype=tl.float32)\n\n    tok_start = tl.zeros([], dtype=tl.int32)   # current token pointer\n\n    while tok_start < kv_len:\n        remaining = kv_len - tok_start\n        block_n = tl.where(remaining < BLOCK_TOK, remaining, BLOCK_TOK)  # scalar int32\n        mask_t = offs_t < block_n                                        # (T,)\n\n        # --- gather token indices -------------------------------------- #\n        idx_ptr  = KV_INDICES + kv_beg + tok_start + offs_t\n        tok_idx  = tl.load(idx_ptr, mask=mask_t, other=0)                # (T,)\n\n        # --- gather KC, KP --------------------------------------------- #\n        kc_ptr = KC + tok_idx[:, None] * D_CKV + offs_ckv[None, :]\n        kp_ptr = KP + tok_idx[:, None] * D_KPE + offs_kpe[None, :]\n\n        kc_blk = tl.load(kc_ptr, mask=mask_t[:, None], other=0).to(tl.float32)  # (T,512)\n        kp_blk = tl.load(kp_ptr, mask=mask_t[:, None], other=0).to(tl.float32)  # (T,64)\n\n        # --- compute logits -------------------------------------------- #\n        l_ckv  = tl.sum(kc_blk * qn[None, :], axis=1)          # (T,)\n        l_kpe  = tl.sum(kp_blk * qp[None, :], axis=1)          # (T,)\n        logits = (l_ckv + l_kpe) * SM_SCALE                   # (T,)\n\n        exp_logits = tl.exp(logits)\n        exp_logits = tl.where(mask_t, exp_logits, 0.0)\n\n        # --- accumulate ------------------------------------------------- #\n        s_sum += tl.sum(exp_logits, axis=0)                               # scalar\n        w_sum += tl.sum(exp_logits[:, None] * kc_blk, axis=0)             # (512,)\n\n        tok_start += BLOCK_TOK\n\n    # ------------------- write back ------------------------------------ #\n    inv_ln2 = 1.4426950408889634  # 1 / ln(2)\n    out_vec = w_sum / s_sum\n    log_s   = tl.log(s_sum) * inv_ln2\n\n    tl.store(ptr_out, out_vec.to(tl.bfloat16))\n    tl.store(ptr_lse, log_s)\n\n\ndef run(\n    q_nope: torch.Tensor,\n    q_pe: torch.Tensor,\n    ckv_cache: torch.Tensor,\n    kpe_cache: torch.Tensor,\n    kv_indptr: torch.Tensor,\n    kv_indices: torch.Tensor,\n    sm_scale: float,\n):\n    \"\"\"\n    Optimized paged-decode kernel for (H=16, D_CKV=512, D_KPE=64, page_size=1).\n\n    Inputs:\n        q_nope     : (B, 16, 512)  bfloat16\n        q_pe       : (B, 16, 64)   bfloat16\n        ckv_cache  : (P, 1, 512)   bfloat16\n        kpe_cache  : (P, 1, 64)    bfloat16\n        kv_indptr  : (B + 1)       int32\n        kv_indices : (N)           int32\n        sm_scale   : float (fp32)\n\n    Returns:\n        dict(output=(B,16,512) bf16, lse=(B,16) fp32)\n    \"\"\"\n    if not torch.cuda.is_available():\n        raise RuntimeError(\"CUDA device is required to run Triton kernels.\")\n\n    # ------------------- validation ------------------- #\n    assert q_nope.dtype == torch.bfloat16 and q_pe.dtype == torch.bfloat16\n    B, H, D_CKV = q_nope.shape\n    assert H == 16 and D_CKV == 512\n    assert q_pe.shape == (B, 16, 64)\n    assert ckv_cache.shape[1] == 1 and kpe_cache.shape[1] == 1            # page_size = 1\n    assert kv_indptr.shape[0] == B + 1\n    assert kv_indices.shape[0] == kv_indptr[-1].item()\n\n    # ---------------- device handling ----------------- #\n    orig_device = q_nope.device\n    cuda_dev = torch.cuda.current_device()\n\n    def _to_cuda(t: torch.Tensor):\n        return t.to(device=cuda_dev, non_blocking=True) if not t.is_cuda else t\n\n    q_nope_d = _to_cuda(q_nope)\n    q_pe_d   = _to_cuda(q_pe)\n    kc_d     = _to_cuda(ckv_cache.squeeze(1))\n    kp_d     = _to_cuda(kpe_cache.squeeze(1))\n    indptr_d = _to_cuda(kv_indptr)\n    indices_d= _to_cuda(kv_indices)\n\n    # ---------------- output buffers ------------------ #\n    out_d = torch.empty((B, H, 512), dtype=torch.bfloat16, device=cuda_dev)\n    lse_d = torch.empty((B, H), dtype=torch.float32, device=cuda_dev)\n\n    # ---------------- kernel launch ------------------- #\n    BLOCK_TOK = 128\n    grid = (B * H,)\n\n    _paged_decode_kernel[grid](\n        q_nope_d,\n        q_pe_d,\n        kc_d,\n        kp_d,\n        indices_d,\n        indptr_d,\n        float(sm_scale),\n        out_d,\n        lse_d,\n        B=B,\n        H=H,\n        D_CKV=512,\n        D_KPE=64,\n        BLOCK_TOK=BLOCK_TOK,\n        num_warps=8,\n        num_stages=4,\n    )\n\n    # --------------- move outputs back --------------- #\n    if orig_device.type == \"cpu\":\n        out_d = out_d.cpu()\n        lse_d = lse_d.cpu()\n    elif orig_device != out_d.device:\n        out_d = out_d.to(orig_device)\n        lse_d = lse_d.to(orig_device)\n\n    return out_d, lse_d"
    }
  ],
  "description": "o3 optimized kernel for mla_paged_decode_h16_ckv512_kpe64_ps1 (round 4)"
}